{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint,uniform\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from  scikeras.wrappers import KerasClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    return train_data\n",
    "train_data = load_data()\n",
    "target_data = train_data[\"Personality\"].copy()\n",
    "training_data = train_data.drop(columns=[\"Personality\",\"id\"])\n",
    "\n",
    "training_data['Socializing_effect'] = training_data['Social_event_attendance'] + training_data['Going_outside'] \n",
    "training_data['probability_of_having_friends'] = training_data['Socializing_effect'] / (training_data['Socializing_effect'].max() + 1e-5)\n",
    "training_data['prob_of_going_outside'] = training_data['Going_outside'] / (training_data['Going_outside'].max() + 1e-5)\n",
    "training_data['online_presence'] = training_data['Post_frequency'] * training_data['Friends_circle_size']\n",
    "\n",
    "num_attributes = training_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_attributes = training_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "\n",
    "corr_matrix = training_data.select_dtypes(include=[np.number]).corr()\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bef05de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean',missing_values=np.nan)),\n",
    "    ('scaler', StandardScaler()),])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', missing_values=np.nan)),\n",
    "    ('one_hot_encoding', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "])\n",
    "\n",
    "pre_processor = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipeline, num_attributes),\n",
    "    ('cat', cat_pipeline, cat_attributes),\n",
    "])\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_processed = pre_processor.fit_transform(training_data)\n",
    "y_processed = le.fit_transform(target_data)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8126fe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights computed\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(train_data):\n",
    "    class_weight = compute_class_weight(class_weight='balanced',classes = np.unique(train_data[\"Personality\"]),y=train_data[\"Personality\"])\n",
    "    class_weight_dict = dict(enumerate(class_weight))\n",
    "    print(\"Class weights computed\")\n",
    "    return class_weight_dict\n",
    "\n",
    "class_weights = compute_class_weights(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9291f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\") ]\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    n_layers = hp.Int(\"no of layers\", 1, 3, default=2)\n",
    "    n_neurons = hp.Int(\"no of neurons\", 32, 512, step=32, default=128)\n",
    "    learning_rate = hp.Float(\"learning rate\", 1e-4, 1e-2, sampling='log', default=1e-3)\n",
    "    optimizer = hp.Choice(\"optimizer\", ['adam', 'sgd'], default='adam')\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(InputLayer(shape=(X_processed.shape[1],)))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(Dense(n_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5963d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=10,\n",
    "                                min_samples_split=2, min_samples_leaf=4,\n",
    "                                max_features=0.3, bootstrap=False,ccp_alpha=0.0,\n",
    "                                class_weight=class_weights, random_state=42)\n",
    "\n",
    "\n",
    "nn_clf = KerasClassifier(model=create_model,model__input_shape=(X_processed.shape[1],),epochs=10,\n",
    "                         batch_size=32,verbose=1,random_state=42)\n",
    "\n",
    "#nn_clf.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25959ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "nn_model = create_model(input_shape=(X_processed.shape[1],))\n",
    "nn_model.fit(X_processed, y_processed, epochs=10, batch_size=32, verbose=1, \n",
    "             validation_data=(X_val, y_val),class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(build_model, max_trials=5, objective='val_accuracy', overwrite=True, project_name='personality_tuning', seed=42)\n",
    "tuner.search(X_processed, y_processed, epochs=10, validation_data=(X_val, y_val), batch_size=32)\n",
    "top_parameters = tuner.get_best_hyperparameters()[0]\n",
    "print(\"Best hyperparameters:\", top_parameters.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_validate(rf_clf, X_processed, y_processed, cv=5, scoring=['accuracy','precision'])\n",
    "cv_scores = pd.DataFrame(cv_scores)\n",
    "print(\"Cross-validation scores for Random Forest Classifier:\",cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'classifier__n_estimators': randint(100,500),\n",
    "    'classifier__max_depth': randint(0,20),\n",
    "    'classifier__min_samples_split': randint(2,10),\n",
    "    'classifier__min_samples_leaf': randint(0,10),\n",
    "    'classifier__max_features': ['sqrt', 'log2', 0.3],\n",
    "    'classifier__ccp_alpha': uniform(0,0.1),\n",
    "    'classifier__bootstrap': [True, False]\n",
    "}\n",
    "# Perform RandomizedSearchCV with SVC-specific parameters\n",
    "random_search = RandomizedSearchCV(estimator=rf_clf, param_distributions=param_dict, n_iter=10,\n",
    "                                   scoring='accuracy', cv=10, verbose=1, random_state=42, n_jobs=-1,\n",
    "                                   error_score='raise')\n",
    "random_search.fit(training_data, target_data)\n",
    "print(random_search.best_params_, random_search.best_score_)\n",
    "print(\"random_search completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prd_scores = cross_val_predict(rf_clf, training_data ,target_data, cv=20,method='predict_proba')\n",
    "print(prd_scores)\n",
    "fpr, tpr, thresholds = roc_curve(target_data, prd_scores[:, 1])\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, label=label, linewidth=2)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curve(fpr, tpr, label='ROC Curve')\n",
    "print(\"Model training and evaluation completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
